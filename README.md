# statim-ai-server

- [Done] Create statim-ai-server repo
- [Done] Add .gitignore
- [Done] Initial commit
- [Done] Load handlers in a dynamically
- [Done] Group handlers in folder
- [Done] Rename Executor to handler
- [Done] Rename "text" to prompt
- [Done] Add column to store result on DB
- [Done] Get available models API
- [Done] Fix docker user (myuser)
- [Done] Use poetry instead of requirements
- [Done] Fix docker image name (my-python-app)
- [Done] Test multimodel
- Create .env file
- Make uniform use of Model ID name
- License file
- Save images on the database in base64
- add start processing date
- add end processing date
- Tests
- docker-compose
- Version file
- input validation
 

## What is statim-ai?

Nowdays it is easy to run AI models (for inference) locally or on the cloud without much effort.

statim-ai wants to provide a out-of-box experience running those models locally or on infrastructure without being tied to specific providers and providing quality-of-life features.

## What does it provides?

## How to Run?

## How it works?

## How to add a new model?

## Beware of the model licenses